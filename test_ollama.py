#!/usr/bin/env python3
"""
Test Ollama Integration with ShieldCall VN API

This script verifies that Ollama is properly integrated and responding.
"""

import sys
import json
import requests

OLLAMA_URL = "http://localhost:11434"

def test_ollama_connection():
    """Test if Ollama service is running"""
    print("1Ô∏è‚É£ Testing Ollama Connection...")
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        if response.status_code == 200:
            print("   ‚úÖ Ollama is running on port 11434")
            return True
        else:
            print(f"   ‚ùå Ollama returned status {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("   ‚ùå Cannot connect to Ollama on http://localhost:11434")
        print("   üí° Make sure Ollama is installed and running")
        return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False

def test_available_models():
    """Check available models"""
    print("\n2Ô∏è‚É£ Checking Available Models...")
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=10)
        if response.status_code == 200:
            data = response.json()
            models = [m.get("name") for m in data.get("models", [])]
            
            if models:
                print(f"   ‚úÖ Found {len(models)} model(s):")
                for model in models:
                    print(f"      - {model}")
                return models
            else:
                print("   ‚ö†Ô∏è  No models found")
                print("   üí° Pull a model: ollama pull neural-chat")
                return []
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return []

def test_generate_response(model):
    """Test generating a response"""
    print(f"\n3Ô∏è‚É£ Testing Response Generation ({model})...")
    try:
        payload = {
            "model": model,
            "prompt": "Xin ch√†o, t√¥i l√† tr·ª£ l√Ω an to√†n ƒëi·ªán tho·∫°i",
            "stream": False
        }
        
        print("   ‚è≥ Generating response (first request may take 10-30 seconds)...")
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json=payload,
            timeout=120  # 2 minute timeout for first request
        )
        
        if response.status_code == 200:
            data = response.json()
            result = data.get("response", "").strip()
            if result:
                print("   ‚úÖ Response generated successfully")
                print(f"   Response: {result[:100]}...")
                return True
            else:
                print("   ‚ùå Empty response")
                return False
        else:
            print(f"   ‚ùå Error {response.status_code}: {response.text}")
            return False
    except requests.exceptions.Timeout:
        print("   ‚ùå Timeout - generation took too long")
        print("   üí° Try with a smaller model")
        return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False

def test_scam_detection(model):
    """Test scam detection"""
    print(f"\n4Ô∏è‚É£ Testing Scam Detection ({model})...")
    try:
        test_text = "Ng√¢n h√†ng y√™u c·∫ßu t√¥i cung c·∫•p m√£ OTP ƒë·ªÉ x√°c minh t√†i kho·∫£n"
        
        payload = {
            "model": model,
            "prompt": f"""Ph√¢n t√≠ch tin nh·∫Øn sau ƒë·ªÉ ph√°t hi·ªán l·ª´a ƒë·∫£o. 
Tr·∫£ l·ªùi d·∫°ng JSON: {{\"is_scam\": bool, \"risk_score\": 0-100, \"reason\": \"string\"}}
Tin nh·∫Øn: {test_text}""",
            "stream": False
        }
        
        print("   ‚è≥ Analyzing scam indicators...")
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json=payload,
            timeout=120
        )
        
        if response.status_code == 200:
            data = response.json()
            result = data.get("response", "").strip()
            
            # Try to extract JSON
            import re
            json_match = re.search(r'\{.*\}', result, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                print("   ‚úÖ Scam detection working")
                print(f"   Analysis: {json.dumps(analysis, indent=2)}")
                return True
            else:
                print("   ‚ö†Ô∏è  Response not in JSON format")
                print(f"   Response: {result[:100]}...")
                return True  # Still counts as working
        else:
            print(f"   ‚ùå Error {response.status_code}")
            return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False

def test_django_integration():
    """Test Django integration"""
    print("\n5Ô∏è‚É£ Testing Django Integration...")
    try:
        from django.conf import settings
        from api.utils.ollama_client import is_ollama_available, get_available_models
        
        print("   ‚úÖ ollama_client module imported successfully")
        
        if is_ollama_available():
            print("   ‚úÖ Ollama detected by Django app")
            models = get_available_models()
            print(f"   ‚úÖ Found {len(models)} model(s) via Django")
            return True
        else:
            print("   ‚ö†Ô∏è  Ollama not detected by Django app")
            print("   üí° Make sure Ollama is running")
            return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False

def main():
    print("=" * 60)
    print("ShieldCall VN API - Ollama Integration Test")
    print("=" * 60)
    
    results = []
    
    # Test 1: Connection
    if not test_ollama_connection():
        print("\n" + "=" * 60)
        print("‚ùå Ollama is not running!")
        print("Follow these steps:")
        print("1. Download from https://ollama.ai")
        print("2. Install and run Ollama")
        print("3. Pull a model: ollama pull neural-chat")
        print("4. Run this test again")
        print("=" * 60)
        return 1
    
    results.append(True)
    
    # Test 2: Models
    models = test_available_models()
    results.append(bool(models))
    
    if models:
        # Use first available model
        model = models[0]
        
        # Test 3: Response generation
        results.append(test_generate_response(model))
        
        # Test 4: Scam detection
        results.append(test_scam_detection(model))
    else:
        print("\nüí° Pull a model first:")
        print("   ollama pull neural-chat")
        return 1
    
    # Test 5: Django integration
    try:
        results.append(test_django_integration())
    except ImportError:
        print("\n5Ô∏è‚É£ Testing Django Integration...")
        print("   ‚ö†Ô∏è  Django test skipped (not in Django context)")
        results.append(True)
    
    # Summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    passed = sum(1 for r in results if r)
    total = len(results)
    
    print(f"Passed: {passed}/{total}")
    
    if passed == total:
        print("\n‚úÖ All tests passed! Ollama integration is working correctly.")
        print("\nYou can now:")
        print("1. Run the API: python manage.py runserver 0.0.0.0:8001")
        print("2. Test endpoints: python test_api.py")
        print("3. Chat will use Ollama automatically")
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) failed")
        print("See details above for troubleshooting")
        return 1

if __name__ == "__main__":
    sys.exit(main())
